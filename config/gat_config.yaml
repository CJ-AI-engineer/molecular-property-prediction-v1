data:
  dataset: BBBP
  num_tasks: 1
  split_ratios:
  - 0.8
  - 0.1
  - 0.1
model:
  dropout: 0.1
  hidden_dim: 128
  num_heads: 4
  num_layers: 5
  type: gat
optimizer:
  betas:
  - 0.9
  - 0.999
  type: adam
scheduler:
  factor: 0.5
  patience: 10
  type: reduce_on_plateau
training:
  batch_size: 32
  epochs: 100
  learning_rate: 0.001
  num_workers: 4
  patience: 20
  weight_decay: 1.0e-05
