# Default Configuration Template
# This serves as a reference for all available options

# Model Configuration
model:
  type: gcn                    # Model architecture: gcn, gin, gat, gin_edge
  node_feat_dim: 50           # Node feature dimension (auto-detected from data)
  edge_feat_dim: 10           # Edge feature dimension (auto-detected from data)
  hidden_dim: 128             # Hidden dimension for graph layers
  num_layers: 5               # Number of graph convolutional layers
  num_tasks: 1                # Number of prediction tasks (auto-detected from data)
  dropout: 0.1                # Dropout probability
  pooling: mean               # Graph pooling: mean, add, max, attention, set2set
  use_residual: true          # Use residual connections (GCN)
  use_batch_norm: true        # Use batch normalization (GCN)
  num_heads: 4                # Number of attention heads (GAT only)

# Data Configuration
data:
  dataset: BBBP               # Dataset name: BBBP, HIV, ESOL, FreeSolv, QM9
  data_root: data/processed   # Root directory for processed data
  batch_size: 32              # Batch size for training
  num_workers: 4              # Number of data loading workers
  split_type: random          # Split strategy: random, scaffold, stratified, temporal
  split_ratios: [0.8, 0.1, 0.1]  # Train/val/test split ratios
  seed: 42                    # Random seed for splitting

# Training Configuration
training:
  task_type: classification   # Task type: classification, regression
  epochs: 100                 # Maximum number of training epochs
  patience: 20                # Early stopping patience
  gradient_clip: 1.0          # Gradient clipping (0 = no clipping)
  min_delta: 0.0              # Minimum improvement for early stopping

# Optimizer Configuration
optimizer:
  type: adam                  # Optimizer: adam, adamw, sgd, rmsprop
  lr: 0.001                   # Learning rate
  weight_decay: 1e-5          # Weight decay (L2 regularization)
  betas: [0.9, 0.999]         # Adam betas
  momentum: 0.9               # SGD momentum
  nesterov: true              # Use Nesterov momentum (SGD)

# Scheduler Configuration
scheduler:
  type: reduce_on_plateau     # Scheduler: none, step, exponential, reduce_on_plateau, cosine, one_cycle
  mode: min                   # Mode for ReduceLROnPlateau: min or max
  factor: 0.5                 # Factor to reduce LR
  patience: 10                # Patience for ReduceLROnPlateau
  step_size: 30               # Step size for StepLR
  gamma: 0.1                  # Gamma for StepLR/ExponentialLR
  min_lr: 1e-6                # Minimum learning rate

# Loss Configuration
loss:
  type: auto                  # Loss function: auto (inferred from task_type), focal, ranking
  pos_weight: null            # Positive class weight for BCE (null = auto-compute)
  focal_alpha: 0.25           # Alpha for focal loss
  focal_gamma: 2.0            # Gamma for focal loss

# Experiment Configuration
experiment:
  name: null                  # Experiment name (auto-generated if null)
  save_dir: ./checkpoints     # Directory to save checkpoints
  log_dir: ./logs             # Directory to save logs
  results_dir: ./results      # Directory to save results
  seed: 42                    # Global random seed
  use_wandb: false            # Use Weights & Biases
  use_mlflow: false           # Use MLflow
  wandb_project: molecular-property-prediction  # W&B project name
  wandb_entity: null          # W&B entity (username/team)
  mlflow_tracking_uri: null   # MLflow tracking URI

# Device Configuration
device:
  gpu: null                   # GPU ID (null = auto-detect, -1 = all GPUs)
  no_cuda: false              # Force CPU usage
  deterministic: false        # Use deterministic algorithms (slower but reproducible)

# Augmentation Configuration (optional)
augmentation:
  enabled: false              # Enable data augmentation
  drop_nodes: 0.1             # Probability of dropping nodes
  drop_edges: 0.1             # Probability of dropping edges
  mask_features: 0.1          # Probability of masking features
  noise_std: 0.01             # Standard deviation of Gaussian noise
