# Deep Ensemble Configuration
# Train multiple models for uncertainty quantification
# Use with scripts/train_ensemble.py (to be implemented)

# Model Configuration
model:
  type: gcn
  hidden_dim: 128
  num_layers: 5
  dropout: 0.1
  pooling: mean
  use_residual: true
  use_batch_norm: true

# Ensemble Configuration
ensemble:
  n_models: 5                 # Number of models in ensemble
  different_seeds: true       # Use different random seeds
  different_init: true        # Use different weight initialization
  
# Data Configuration
data:
  dataset: BBBP
  data_root: data/processed
  batch_size: 32
  num_workers: 4
  split_type: scaffold
  split_ratios: [0.8, 0.1, 0.1]
  seed: 42                    # Base seed (will be modified for each model)

# Training Configuration
training:
  task_type: classification
  epochs: 150
  patience: 30
  gradient_clip: 1.0

# Optimizer Configuration
optimizer:
  type: adam
  lr: 0.001
  weight_decay: 1e-5

# Scheduler Configuration
scheduler:
  type: reduce_on_plateau
  mode: max
  factor: 0.5
  patience: 15
  min_lr: 1e-6

# Experiment Configuration
experiment:
  name: bbbp_gcn_ensemble
  save_dir: ./checkpoints
  log_dir: ./logs
  results_dir: ./results
  seed: 42
  use_wandb: false

# Device Configuration
device:
  gpu: 0

# Uncertainty Quantification:
# - Ensemble provides mean prediction and variance
# - Variance indicates prediction uncertainty
# - High uncertainty â†’ active learning opportunity
# - Calibration: plot predicted variance vs actual error
